# OTTO Recommender System â€“ Days 1 to 20

This repository documents a self-directed Kaggle project exploring the OTTO Recommender System dataset.

## ðŸ›’ OTTO Recommender System (Kaggle Project)

This repository documents my learning journey through the OTTO RecSys Kaggle competition.  
The project is structured in daily progress notebooks, each extracting and engineering features from clickstream data.

âœ… Purpose: Strengthen my data science foundations  


Notebook highlights:
- Data loading & EDA
- Behavior statistics & funnels
- Sequential pattern mining
- Item-level popularity features

## âœ… Completed Days

## ðŸ“˜ Day 1 â€“ Data Loading & Exploration

### ðŸŽ¯ Goal  
Load the raw training data and understand its structure.

### ðŸ§© Workflow  
- Load `train.parquet` into a DataFrame  
- Check basic columns: `session`, `aid`, `ts`, `type`  
- Examine event distribution and timestamp ranges  

### ðŸ“š Knowledge Points  
- Using `pd.read_parquet`  
- Understanding event logs in recommendation datasets  
- Datetime conversion and `value_counts`

## ðŸ“˜ Day 2 â€“ Session Behavior Analysis

### ðŸŽ¯ Goal  
Analyze user behaviors at the session level.

### ðŸ§© Workflow  
- Extract session duration  
- Count number of actions per session  
- Explore interaction frequency by action type  

### ðŸ“š Knowledge Points  
- Grouping and aggregating sessions  
- Session-based recommendation metrics  
- Action type segmentation

## ðŸ“˜ Day 3 â€“ Conversion Funnel Analysis

### ðŸŽ¯ Goal  
Explore the behavior funnel: click â†’ cart â†’ order.

### ðŸ§© Workflow  
- Compute counts and rates for clicks, carts, and orders  
- Analyze conversion ratios  
- Plot funnel chart for behavior conversion  

### ðŸ“š Knowledge Points  
- Conversion rate computation  
- `groupby()` with multiple filters  
- Funnel chart design principles

## ðŸ“˜ Day 4 â€“ Sequential Pattern & Action Time Gap

### ðŸŽ¯ Goal  
Analyze time intervals between actions and sequential behavior patterns.

### ðŸ§© Workflow  
- Sort actions by timestamp  
- Compute time deltas within each session  
- Analyze most common action sequences  

### ðŸ“š Knowledge Points  
- `groupby().diff()` for time gaps  
- Action sequence frequency analysis  
- Temporal behavior understanding

## ðŸ“˜ Day 5 â€“ Item-Level Statistics

### ðŸŽ¯ Goal  
Understand item popularity and engagement by event type.

### ðŸ§© Workflow  
- Compute total clicks, carts, orders per item  
- Rank items by interaction volume  
- Create visualizations of top items  

### ðŸ“š Knowledge Points  
- Multi-index aggregation  
- Sorting and ranking aids  
- Feature engineering for items

## ðŸ“˜ Day 6 â€“ Session-Level Feature Engineering

### ðŸŽ¯ Goal  
Extract session-level statistical features.

### ðŸ§© Workflow  
- Count unique items per session  
- Session duration and average time per event  
- Item diversity and entropy metrics  

### ðŸ“š Knowledge Points  
- Grouping by session for feature extraction  
- Use of `nunique`, `mean`, and entropy  
- Session-based modeling prep

## ðŸ“˜ Day 7 â€“ Candidate Generation: Popularity-Based Recall

### ðŸŽ¯ Goal

Generate session-item candidate pairs based on item popularity (clicks, carts, orders). This is a simple baseline recall strategy.

### ðŸ§© Workflow

1. Load training dataset (`train.parquet`)
2. Map action types (0/1/2) to strings: `clicks`, `carts`, `orders`
3. Aggregate most frequent items by action type
4. Create candidate pairs by combining each session with top-N popular items
5. Save as `popularity_candidates.parquet`

### ðŸ“š Knowledge Points

- `groupby().size()` for aggregation
- Use of `np.repeat` and `np.tile` for matrix construction
- Understanding candidate recall strategies in recommendation systems

## ðŸ“˜ Day 8 â€“ Candidate Generation: Co-visitation Matrix

### ðŸŽ¯ Goal  
Build a candidate recall strategy based on co-visitation. Items that appear together in sessions are likely to be relevant.

### ðŸ§© Workflow  
- Load training session logs  
- Build item-to-item co-visitation matrix from user sessions  
- Extract top co-visited items as candidate pairs  
- Save results for next-step recall/modeling

### ðŸ“š Knowledge Points  
- Nested dictionary and defaultdict usage  
- Pairwise item interactions in collaborative filtering  
- Candidate generation using item-item relationships

## ðŸ“˜ Day 9: Session-level Aggregate Features

### ðŸŽ¯ Goal  
This notebook computes session-level aggregate features for the OTTO dataset.  
These features include:
- Total interactions per session
- Unique items per session
- Average interaction time difference per session

### ðŸ§© Workflow  
1. Load train and test parquet files.
2. Combine datasets to ensure consistent statistics.
3. Compute total interactions per session.
4. Compute unique items per session.
5. Compute average time difference per session.
6. Merge features back to train and test datasets.

### ðŸ“š Knowledge Points  
- `train_day9.parquet`
- `test_day9.parquet`


## ðŸ“‚ Structure

- `notebook/`: Contains Day 1â€“20 Jupyter Notebooks.
- `visualizations/`: Visual output from matplotlib charts.
- `README.md`: Project overview and progress.

## ðŸ“Œ Author

Prepared by Zhang JingHao 
ðŸŽ¯ Goal: Prepare for research and scholarship application at NTU Singapore
